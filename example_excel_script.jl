# SDMX Excel Multi-Sheet Transformation
# Generated by SDMX.jl on 2025-01-07T15:40:00
# Processes complex Excel files with multiple sheets and metadata

# Note: This example uses Tidier.jl for data transformation syntax.
# Install with: julia -e "using Pkg; Pkg.add(\"Tidier\")"
using DataFrames, XLSX, Tidier, Statistics

# === EXCEL ANALYSIS ===
# Detected sheets: ["Metadata", "Data_2020", "Data_2021", "Data_2022", "Codelist", "Notes"]
# Primary data sheet: Data_2022
# Metadata extraction: Headers in rows 1-3, data starts row 4

println("Opening Excel file for multi-sheet processing...")
excel_file = "pacific_stats_workbook.xlsx"

# === METADATA EXTRACTION ===
println("\nExtracting metadata from Excel sheets...")

# Read metadata sheet for context
metadata_sheet = XLSX.readtable(excel_file, "Metadata") |> DataFrame
println("✓ Metadata sheet loaded: $(nrow(metadata_sheet)) rows")

# Extract key metadata information
report_title = metadata_sheet[1, 2]  # Assuming title in B1
report_period = metadata_sheet[2, 2]  # Assuming period in B2  
data_source = metadata_sheet[3, 2]   # Assuming source in B3
contact_info = metadata_sheet[4, 2]  # Assuming contact in B4

println("Report: $report_title")
println("Period: $report_period") 
println("Source: $data_source")

# Read codelist sheet for validation
codelist_sheet = XLSX.readtable(excel_file, "Codelist") |> DataFrame
country_codes = unique(codelist_sheet[!, :country_code])
indicator_codes = unique(codelist_sheet[!, :indicator_code])

println("✓ Available country codes: $(join(country_codes, ", "))")
println("✓ Available indicator codes: $(join(indicator_codes, ", "))")

# === DATA LOADING FROM MULTIPLE SHEETS ===
println("\nLoading data from multiple year sheets...")

# Function to read and standardize data from each year sheet
function read_year_data(sheet_name, year)
    println("  Processing $sheet_name...")
    
    # Read data starting from row 4 (after headers)
    raw_data = XLSX.readtable(excel_file, sheet_name, first_row=4) |> DataFrame
    
    # Add year column
    raw_data[!, :data_year] = year
    
    # Standardize column names (remove spaces, make lowercase)
    rename!(raw_data, [Symbol(replace(lowercase(string(col)), r"\s+" => "_")) for col in names(raw_data)])
    
    return raw_data
end

# Load data from each year sheet
data_sheets = [
    ("Data_2020", "2020"),
    ("Data_2021", "2021"), 
    ("Data_2022", "2022")
]

yearly_data = []
for (sheet, year) in data_sheets
    try
        year_df = read_year_data(sheet, year)
        push!(yearly_data, year_df)
        println("  ✓ Loaded $(nrow(year_df)) rows from $sheet")
    catch e
        println("  ⚠ Failed to load $sheet: $e")
    end
end

# Combine all yearly data
if !isempty(yearly_data)
    combined_data = vcat(yearly_data..., cols=:union)
    println("✓ Combined data: $(nrow(combined_data)) total rows")
else
    error("❌ No data sheets could be loaded!")
end

# === DATA TRANSFORMATIONS ===
println("\nStarting Excel data transformations...")

transformed_data = combined_data |>
    # Step 1: Handle Excel-specific issues
    @mutate(
        # Convert Excel dates that might be stored as numbers
        TIME_PERIOD = case_when(
            !is.na(data_year) ~ data_year,
            !is.na(year) ~ as.character(year),
            !is.na(reporting_year) ~ as.character(reporting_year),
            .default = "9999"  # TODO: Handle missing years
        ),
        
        # Clean up country names that might have Excel formatting issues
        country_clean = case_when(
            !is.na(country) ~ str_trim(str_to_title(country)),
            !is.na(country_name) ~ str_trim(str_to_title(country_name)),
            !is.na(territory) ~ str_trim(str_to_title(territory)),
            .default = "Unknown"
        )
    ) |>
    
    # Step 2: Map to SDMX country codes using codelist
    @mutate(GEO_PICT = case_when(
        country_clean == "Fiji" ~ "FJ",
        country_clean == "Vanuatu" ~ "VU",
        country_clean == "Samoa" ~ "WS", 
        country_clean == "Tonga" ~ "TO",
        country_clean == "Cook Islands" ~ "CK",
        country_clean == "Palau" ~ "PW",
        country_clean == "Papua New Guinea" ~ "PG",
        country_clean == "Solomon Islands" ~ "SB",
        country_clean == "Tuvalu" ~ "TV",
        country_clean == "Niue" ~ "NU",
        country_clean == "French Polynesia" ~ "PF",
        country_clean == "New Caledonia" ~ "NC",
        str_detect(country_clean, "Marshall") ~ "MH",
        str_detect(country_clean, "Micronesia") ~ "FM",
        str_detect(country_clean, "Kiribati") ~ "KI",
        str_detect(country_clean, "Nauru") ~ "NR",
        .default = toupper(substr(country_clean, 1, 2))  # TODO: Verify unmapped countries
    )) |>
    
    # Step 3: Handle multiple possible indicator columns
    @mutate(
        indicator_clean = case_when(
            !is.na(indicator) ~ str_trim(indicator),
            !is.na(indicator_name) ~ str_trim(indicator_name),
            !is.na(measure) ~ str_trim(measure),
            !is.na(variable) ~ str_trim(variable),
            .default = "Unknown"  # TODO: Handle missing indicators
        )
    ) |>
    
    # Step 4: Map indicators to SDMX codes based on patterns
    @mutate(INDICATOR = case_when(
        str_detect(indicator_clean, "(?i)gdp|gross.*domestic") ~ "GDP_PC",
        str_detect(indicator_clean, "(?i)population|inhabitants") ~ "POP_TOT",
        str_detect(indicator_clean, "(?i)tourism|visitor|arrival") ~ "TOUR_ARR", 
        str_detect(indicator_clean, "(?i)export") ~ "EXP_GOODS",
        str_detect(indicator_clean, "(?i)import") ~ "IMP_GOODS",
        str_detect(indicator_clean, "(?i)inflation|cpi") ~ "PRICES_CPI",
        str_detect(indicator_clean, "(?i)employment|labor") ~ "EMPL_RATE",
        str_detect(indicator_clean, "(?i)education|school") ~ "EDU_ENROL",
        str_detect(indicator_clean, "(?i)health|mortality") ~ "HEALTH_MORT",
        str_detect(indicator_clean, "(?i)environment|emission") ~ "ENV_EMIS",
        .default = "OTHER_IND"  # TODO: Map remaining indicators
    )) |>
    
    # Step 5: Handle multiple possible value columns  
    @mutate(
        raw_value = case_when(
            !is.na(value) ~ value,
            !is.na(obs_value) ~ obs_value,
            !is.na(amount) ~ amount,
            !is.na(number) ~ number,
            !is.na(count) ~ count,
            !is.na(rate) ~ rate,
            !is.na(percentage) ~ percentage,
            .default = missing
        )
    ) |>
    
    # Step 6: Clean observation values (handle Excel quirks)
    @mutate(OBS_VALUE = case_when(
        is.na(raw_value) ~ missing,
        raw_value == "N/A" ~ missing,
        raw_value == "#N/A" ~ missing,  # Excel error value
        raw_value == "#DIV/0!" ~ missing,  # Excel division by zero
        raw_value == "#VALUE!" ~ missing,  # Excel value error
        raw_value == "#REF!" ~ missing,   # Excel reference error  
        raw_value == "..." ~ missing,
        raw_value == "-" ~ missing,
        raw_value == "" ~ missing,
        str_detect(as.character(raw_value), "^[0-9,.]+$") ~ as.numeric(str_replace_all(as.character(raw_value), ",", "")),
        .default = missing  # TODO: Review non-numeric values
    )) |>
    
    # Step 7: Add required SDMX dimensions
    @mutate(
        FREQ = "A",  # Annual frequency
        
        # Determine unit of measure from context
        UNIT_MEASURE = case_when(
            str_detect(indicator_clean, "(?i)gdp|dollar|USD|revenue|income") ~ "USD",
            str_detect(indicator_clean, "(?i)population|people|person") ~ "NUMBER", 
            str_detect(indicator_clean, "(?i)percent|rate|%") ~ "PERCENT",
            str_detect(indicator_clean, "(?i)ton|tonne|kg") ~ "KG",
            str_detect(indicator_clean, "(?i)hectare|area") ~ "HA",
            .default = "PURE_NUMB"
        ),
        
        # Set unit multiplier based on typical scales
        UNIT_MULT = case_when(
            str_detect(indicator_clean, "(?i)gdp") ~ "6",  # Millions
            str_detect(indicator_clean, "(?i)population") ~ "0",  # Units
            str_detect(indicator_clean, "(?i)thousand") ~ "3",   # Thousands
            str_detect(indicator_clean, "(?i)million") ~ "6",    # Millions
            str_detect(indicator_clean, "(?i)billion") ~ "9",    # Billions
            .default = "0"  # Units
        ),
        
        # Extract data quality information from Excel comments/formatting
        OBS_STATUS = case_when(
            !is.na(footnote) ~ "C",  # Commented
            !is.na(data_quality) && data_quality == "provisional" ~ "P",  # Provisional
            !is.na(data_quality) && data_quality == "estimated" ~ "E",   # Estimated
            is.na(OBS_VALUE) ~ "M",  # Missing
            .default = ""  # Normal value
        )
    ) |>
    
    # Step 8: Filter and finalize
    @filter(
        !is.na(GEO_PICT),
        !is.na(INDICATOR),
        !is.na(TIME_PERIOD),
        GEO_PICT != "Unknown",
        INDICATOR != "OTHER_IND" | !is.na(OBS_VALUE)  # Keep unmapped if has value
    ) |>
    
    # Step 9: Select final SDMX columns
    @select(
        FREQ, GEO_PICT, INDICATOR, TIME_PERIOD,
        OBS_VALUE, UNIT_MEASURE, UNIT_MULT, OBS_STATUS
    ) |>
    
    # Step 10: Remove duplicates and sort
    @distinct(FREQ, GEO_PICT, INDICATOR, TIME_PERIOD, .keep_all = true) |>
    @arrange(GEO_PICT, INDICATOR, TIME_PERIOD)

println("✅ Excel transformation completed!")
println("Processed $(length(data_sheets)) sheets into $(nrow(transformed_data)) observations")

# === EXCEL-SPECIFIC VALIDATION ===
println("\n=== EXCEL DATA VALIDATION ===")

# Check if all sheets were processed
sheets_processed = length(yearly_data)
sheets_expected = length(data_sheets)
println("Sheets processed: $sheets_processed / $sheets_expected")

# Validate year coverage
years_found = sort(unique(skipmissing(transformed_data.TIME_PERIOD)))
years_expected = [sheet[2] for sheet in data_sheets]
missing_years = setdiff(years_expected, years_found)

if isempty(missing_years)
    println("✓ All expected years present: $(join(years_found, ", "))")
else
    println("⚠ Missing years: $(join(missing_years, ", "))")
end

# Check for Excel-specific data issues
excel_errors = filter(!ismissing, transformed_data.OBS_VALUE)
if any(x -> x < 0 && str_detect(string(x), "#"), excel_errors)
    println("⚠ Potential Excel error values detected in data")
end

# Validate against codelist
unmapped_countries = setdiff(unique(skipmissing(transformed_data.GEO_PICT)), country_codes)
if !isempty(unmapped_countries)
    println("⚠ Countries not in codelist: $(join(unmapped_countries, ", "))")
end

unmapped_indicators = setdiff(unique(skipmissing(transformed_data.INDICATOR)), indicator_codes)
if !isempty(unmapped_indicators)
    println("⚠ Indicators not in codelist: $(join(unmapped_indicators, ", "))")
end

# Data completeness by year
println("\n=== DATA COMPLETENESS BY YEAR ===")
for year in years_found
    year_data = filter(row -> row.TIME_PERIOD == year, transformed_data)
    valid_obs = sum(!ismissing.(year_data.OBS_VALUE))
    total_obs = nrow(year_data)
    completeness = round(valid_obs/total_obs*100, digits=1)
    println("$year: $valid_obs/$total_obs observations ($completeness% complete)")
end

# === OUTPUT GENERATION ===
println("\n=== GENERATING OUTPUTS ===")

# Main SDMX-CSV file
output_filename = "sdmx_excel_$(Dates.format(now(), "yyyymmdd_HHMMSS")).csv"
CSV.write(output_filename, transformed_data)
println("✅ Main SDMX-CSV: $output_filename")

# Metadata file with Excel extraction details
metadata_filename = replace(output_filename, ".csv" => "_metadata.txt")
open(metadata_filename, "w") do f
    write(f, """SDMX Excel Multi-Sheet Extraction Report

Generated: $(now())
Source Excel File: $excel_file
Report Title: $report_title
Report Period: $report_period
Data Source: $data_source
Contact: $contact_info

Sheets Processed:
$(join(["- $sheet ($year)" for (sheet, year) in data_sheets], "\n"))

Data Summary:
- Total observations: $(nrow(transformed_data))
- Countries: $(length(unique(skipmissing(transformed_data.GEO_PICT))))
- Indicators: $(length(unique(skipmissing(transformed_data.INDICATOR))))  
- Time periods: $(join(years_found, ", "))

Quality Notes:
- Metadata extracted from dedicated sheet
- Country codes validated against codelist
- Excel error values (#N/A, #DIV/0!, etc.) converted to missing
- Data quality flags preserved from source

Manual Review Required:
- Verify country code mappings
- Confirm indicator classifications
- Check unit of measure assignments
- Validate any Excel formatting assumptions
""")
end
println("✅ Metadata report: $metadata_filename")

# Summary statistics by sheet
stats_filename = replace(output_filename, ".csv" => "_stats.csv")
sheet_stats = DataFrame(
    Sheet = [sheet[1] for sheet in data_sheets],
    Year = [sheet[2] for sheet in data_sheets],
    Original_Rows = [nrow(df) for df in yearly_data],
    Final_Observations = [nrow(filter(row -> row.TIME_PERIOD == sheet[2], transformed_data)) for sheet in data_sheets],
    Data_Completeness = [round(sum(!ismissing.(filter(row -> row.TIME_PERIOD == sheet[2], transformed_data).OBS_VALUE)) / 
                               nrow(filter(row -> row.TIME_PERIOD == sheet[2], transformed_data)) * 100, digits=1) 
                        for sheet in data_sheets]
)
CSV.write(stats_filename, sheet_stats)
println("✅ Sheet statistics: $stats_filename")

println("\n=== EXCEL PROCESSING COMPLETED ===")
println("📊 Successfully extracted data from $(length(data_sheets)) Excel sheets")
println("🗂️  Metadata and context preserved from source workbook")
println("✅ $(nrow(transformed_data)) observations ready for SDMX submission")
println("📋 Review metadata report for extraction details")

# Display sample output
println("\n=== SAMPLE EXCEL OUTPUT ===")
println(first(transformed_data, 8))